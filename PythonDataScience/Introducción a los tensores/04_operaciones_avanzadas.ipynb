{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28cdef4-65bf-419a-9011-a531d78f8af2",
   "metadata": {},
   "source": [
    "### 1. **Multiplicación de Matrices (`torch.mm`)**\n",
    "\n",
    "`torch.mm` es una función para multiplicación de matrices, clave en redes neuronales ya que cada capa de neuronas es básicamente una operación de este tipo. Los pesos de las redes se almacenan en matrices, y la multiplicación matricial es la base para calcular los resultados de las capas de la red.\n",
    "\n",
    "#### Ejemplo\n",
    "Imaginemos una red con una capa densa de neuronas, donde cada neurona toma un conjunto de entradas (representadas como un vector) y produce una salida.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Pesos de la capa (matriz 2x2) y entrada de datos (vector 2x1)\n",
    "weights = torch.tensor([[0.2, 0.8], [0.5, 0.7]])\n",
    "inputs = torch.tensor([[1.0], [2.0]])\n",
    "\n",
    "# Multiplicación de la matriz de pesos por el vector de entrada\n",
    "output = torch.mm(weights, inputs)\n",
    "print(output)  # tensor([[1.8], [1.9]])\n",
    "```\n",
    "\n",
    "#### ¿Cuándo usarlo?\n",
    "1. **Propagación en redes neuronales**: en cada capa de una red, los datos de entrada se multiplican por los pesos de la capa.\n",
    "2. **Transformaciones lineales**: se usa en cualquier situación que requiera aplicar una transformación lineal (e.g., rotaciones, escalados).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Multiplicación Matriz-Vector (`torch.mv`)**\n",
    "\n",
    "Esta operación multiplica una matriz 2D con un vector 1D, una variación de `torch.mm` que optimiza la multiplicación al reducir una dimensión. Es ideal en redes neuronales donde una capa tiene un vector de entrada.\n",
    "\n",
    "#### Ejemplo\n",
    "En un modelo de regresión lineal, los datos de entrada (características de un conjunto de viviendas, por ejemplo) se multiplican por los pesos del modelo para obtener la predicción.\n",
    "\n",
    "```python\n",
    "# Supongamos que tenemos características de 3 casas (3 características cada una)\n",
    "features = torch.tensor([[1.0, 0.5, 2.0], [2.0, 1.0, 3.0], [1.5, 2.0, 0.5]])\n",
    "weights = torch.tensor([0.3, 0.6, 0.9])\n",
    "\n",
    "# Multiplicación para calcular el precio estimado de cada casa\n",
    "predictions = torch.mv(features, weights)\n",
    "print(predictions)  # tensor([2.85, 5.10, 2.55])\n",
    "```\n",
    "\n",
    "#### ¿Cuándo usarlo?\n",
    "1. **Modelos de regresión**: en regresiones lineales donde cada entrada es un vector de características.\n",
    "2. **Predicciones basadas en características**: situaciones en las que una única predicción depende de varias características ponderadas.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Producto Punto (`torch.dot`)**\n",
    "\n",
    "El producto punto de dos vectores calcula un valor escalar que representa la “proximidad” de dos vectores en el espacio, útil en cálculos de similitud y en operaciones básicas de redes neuronales.\n",
    "\n",
    "#### Ejemplo\n",
    "El producto punto es esencial en algoritmos de similitud como la similitud coseno, que mide la similitud entre vectores de características (por ejemplo, en recomendaciones de productos).\n",
    "\n",
    "```python\n",
    "# Representaciones vectoriales de dos películas\n",
    "vector1 = torch.tensor([0.8, 0.3, 0.1])\n",
    "vector2 = torch.tensor([0.9, 0.4, 0.2])\n",
    "\n",
    "# Producto punto para calcular similitud\n",
    "similarity = torch.dot(vector1, vector2)\n",
    "print(similarity)  # tensor(0.89)\n",
    "```\n",
    "\n",
    "#### ¿Cuándo usarlo?\n",
    "1. **Medir similitud entre vectores**: en sistemas de recomendación para comparar productos o perfiles de usuario.\n",
    "2. **Cálculos básicos en geometría**: para evaluar proyecciones y relaciones entre vectores en espacios geométricos.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Multiplicación de Matrices en Lotes (`torch.bmm`)**\n",
    "\n",
    "`torch.bmm` permite multiplicar matrices en paralelo por lotes, muy útil en redes donde procesamos grandes volúmenes de datos y queremos realizar cálculos eficientes en GPUs.\n",
    "\n",
    "#### Ejemplo\n",
    "Imaginemos un procesamiento en paralelo de múltiples imágenes para una red convolucional, donde cada imagen pasa por una matriz de transformación.\n",
    "\n",
    "```python\n",
    "# Dos lotes de transformaciones y datos\n",
    "batch_transform = torch.tensor([[[0.2, 0.8], [0.5, 0.7]], [[1.0, 0.5], [0.5, 1.0]]])\n",
    "batch_data = torch.tensor([[[1.0, 2.0], [3.0, 4.0]], [[1.5, 2.5], [3.5, 4.5]]])\n",
    "\n",
    "# Multiplicación de matrices en lotes\n",
    "result_batch = torch.bmm(batch_transform, batch_data)\n",
    "print(result_batch)\n",
    "```\n",
    "\n",
    "#### ¿Cuándo usarlo?\n",
    "1. **Procesamiento paralelo**: en redes convolucionales donde varios datos se procesan en paralelo en GPUs.\n",
    "2. **Transformaciones simultáneas**: aplicaciones que requieren transformar múltiples vectores o matrices al mismo tiempo.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Valores y Vectores Propios (`torch.eig`)**\n",
    "\n",
    "Los valores y vectores propios permiten entender las propiedades de una transformación representada por una matriz. Son útiles para identificar direcciones de mayor variación en los datos.\n",
    "\n",
    "#### Ejemplo\n",
    "En procesamiento de imágenes, los valores y vectores propios ayudan a realizar la reducción de dimensionalidad. En el análisis de imágenes de rostros, por ejemplo, podemos identificar las principales direcciones de variación.\n",
    "\n",
    "```python\n",
    "matrix = torch.tensor([[2.0, 1.0], [1.0, 2.0]])\n",
    "eigenvalues, eigenvectors = torch.eig(matrix, eigenvectors=True)\n",
    "print(\"Valores propios:\", eigenvalues)\n",
    "print(\"Vectores propios:\", eigenvectors)\n",
    "```\n",
    "\n",
    "#### ¿Cuándo usarlo?\n",
    "1. **Reducción de dimensionalidad**: en PCA para transformar datos de alta dimensión en un subespacio de menor dimensión.\n",
    "2. **Análisis de estabilidad**: en simulaciones donde los valores propios determinan la estabilidad de un sistema.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Descomposición en Valores Singulares (SVD, `torch.svd`)**\n",
    "\n",
    "La descomposición en valores singulares es clave para la compresión de datos y reducción de dimensionalidad. SVD descompone una matriz en componentes ortogonales, lo que permite analizar los datos en términos de sus componentes principales.\n",
    "\n",
    "#### Ejemplo\n",
    "En sistemas de recomendación, SVD es útil para encontrar factores latentes en matrices de valoraciones (como la relación entre usuarios y productos en una matriz de valoraciones).\n",
    "\n",
    "```python\n",
    "matrix = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "U, S, V = torch.svd(matrix)\n",
    "print(\"U:\", U)\n",
    "print(\"S:\", S)\n",
    "print(\"V:\", V)\n",
    "```\n",
    "\n",
    "#### ¿Cuándo usarlo?\n",
    "1. **Compresión de datos**: en modelos de recomendación para reducir la matriz de valoraciones a sus componentes principales.\n",
    "2. **Análisis de patrones latentes**: en problemas donde queremos identificar los principales componentes que explican la variabilidad de los datos.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Inversa de una Matriz (`torch.inverse`)**\n",
    "\n",
    "La inversa de una matriz es esencial en problemas de optimización y sistemas de ecuaciones lineales, donde queremos resolver sistemas del tipo \\(Ax = b\\).\n",
    "\n",
    "#### Ejemplo\n",
    "Imaginemos un problema de ajuste de curvas, donde se requiere encontrar los parámetros de un modelo lineal que minimicen el error.\n",
    "\n",
    "```python\n",
    "matrix = torch.tensor([[4.0, 7.0], [2.0, 6.0]])\n",
    "inverse_matrix = torch.inverse(matrix)\n",
    "print(inverse_matrix)\n",
    "```\n",
    "\n",
    "#### ¿Cuándo usarlo?\n",
    "1. **Resolución de sistemas lineales**: en problemas de optimización para encontrar los parámetros óptimos.\n",
    "2. **Modelado físico**: en sistemas dinámicos donde la inversión de una matriz describe el comportamiento de un sistema a través del tiempo.\n",
    "\n",
    "---\n",
    "\n",
    "### Resumen Visual de Aplicaciones\n",
    "\n",
    "| Operación               | Uso Común                                       | Ejemplo Real                                                      |\n",
    "|-------------------------|-------------------------------------------------|-------------------------------------------------------------------|\n",
    "| **`torch.mm`**          | Multiplicación de matrices                      | Propagación en capas de redes neuronales                          |\n",
    "| **`torch.mv`**          | Multiplicación matriz-vector                    | Modelos de regresión en sistemas de predicción                    |\n",
    "| **`torch.dot`**         | Producto punto entre vectores                   | Similitud coseno en sistemas de recomendación                     |\n",
    "| **`torch.bmm`**         | Multiplicación de matrices por lotes            | Procesamiento paralelo de datos en redes convolucionales          |\n",
    "| **`torch.eig`**         | Cálculo de valores y vectores propios           | Reducción de dimensionalidad en análisis de imágenes              |\n",
    "| **`torch.svd`**         | Descomposición en valores singulares            | Compresión de datos en sistemas de recomendación                  |\n",
    "|\n",
    "\n",
    " **`torch.inverse`**     | Inversa de matriz para resolver sistemas lineales | Optimización de modelos físicos en simulaciones de dinámica       |\n",
    "\n",
    "Estas operaciones avanzadas son fundamentales en redes neuronales, no solo por el cálculo de pesos, sino también para aplicaciones de reducción de dimensionalidad, compresión de datos y resolución de sistemas de ecuaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ad1dc-f2e5-44b3-b0f3-0f65c86a2137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
