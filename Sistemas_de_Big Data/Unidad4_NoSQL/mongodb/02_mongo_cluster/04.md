## **4. Monitorización y Mantenimiento**

### **4.1. Monitorización de rendimiento**

La monitorización efectiva de MongoDB es fundamental para mantener un sistema saludable y detectar problemas antes de que afecten a los usuarios. A diferencia de simplemente reaccionar ante fallos, una estrategia de monitorización proactiva nos permite identificar tendencias, planificar capacidad y optimizar el rendimiento continuamente. [mongodb](https://www.mongodb.com/resources/products/capabilities/how-to-monitor-mongodb-and-what-metrics-to-monitor)

**Métricas clave de rendimiento:**

La monitorización de MongoDB se organiza en varias categorías de métricas, cada una proporcionando información sobre diferentes aspectos del sistema. [last9](https://last9.io/blog/mongodb-performance-metrics/)

**Métricas de memoria:**

MongoDB utiliza la memoria de forma agresiva para mejorar el rendimiento, manteniendo los datos más accedidos en RAM. Las métricas principales son: [geeksforgeeks](https://www.geeksforgeeks.org/mongodb/monitoring-mongodb-performance-metrics/)

- **resident memory**: Memoria física realmente utilizada por el proceso mongod
- **virtual memory**: Memoria total asignada (incluye archivos mapeados)
- **WiredTiger cache**: Caché interno del motor de almacenamiento
- **page faults**: Accesos a datos no en memoria que requieren leer del disco

```javascript
// Obtener métricas de memoria
db.serverStatus().mem
{
  "bits": 64,
  "resident": 2048,      // MB en RAM
  "virtual": 8192,       // MB virtuales
  "supported": true,
  "mapped": 0,
  "mappedWithJournal": 0
}

// Métricas específicas de WiredTiger
db.serverStatus().wiredTiger.cache
{
  "bytes currently in the cache": 1073741824,  // ~1GB
  "maximum bytes configured": 2147483648,      // 2GB límite
  "pages read into cache": 123456,
  "pages written from cache": 78901,
  "cache overflow score": 0  // >0 indica presión de memoria
}
```

**Ejemplo práctico de análisis de memoria:**

Si observamos que `resident memory` está constantemente cerca del 80-90% de la RAM física del servidor, y `cache overflow score` es mayor que 0, indica que necesitamos más memoria. Podemos verificar si hay page faults frecuentes:

```javascript
// Monitorizar page faults en tiempo real
var before = db.serverStatus().extra_info.page_faults;
sleep(5000);  // Esperar 5 segundos
var after = db.serverStatus().extra_info.page_faults;
print("Page faults/segundo: " + (after - before) / 5);
```

Si obtenemos más de 100 page faults por segundo de forma sostenida, definitivamente necesitamos más RAM o reducir el working set (datos activos).

**Métricas de operaciones:**

MongoDB registra contadores para cada tipo de operación: [last9](https://last9.io/blog/mongodb-performance-metrics/)

```javascript
db.serverStatus().opcounters
{
  "insert": 458923,
  "query": 2341567,
  "update": 678234,
  "delete": 12345,
  "getmore": 456789,    // Operaciones de cursor
  "command": 8901234    // Comandos administrativos
}
```

Para calcular operaciones por segundo (ops), podemos crear un script de monitorización:

```javascript
function calcularOpsSegundo(intervaloSeg) {
  var inicial = db.serverStatus().opcounters;
  sleep(intervaloSeg * 1000);
  var final = db.serverStatus().opcounters;
  
  print("=== Operaciones por segundo ===");
  for (var op in inicial) {
    var ops = (final[op] - inicial[op]) / intervaloSeg;
    print(`${op}: ${ops.toFixed(2)} ops/s`);
  }
}

calcularOpsSegundo(10);  // Medir durante 10 segundos
```

**Métricas de rendimiento de consultas:**

El tiempo de ejecución de consultas es crítico. MongoDB proporciona varias formas de medirlo: [moldstud](https://moldstud.com/articles/p-master-mongodb-performance-metrics-a-pros-guide-to-effective-monitoring)

```javascript
// Analizar plan de ejecución de una consulta
db.pedidos.find({ 
  fecha: { $gte: ISODate("2026-01-01") },
  estado: "pendiente" 
}).explain("executionStats")

// Salida relevante:
{
  "executionStats": {
    "executionTimeMillis": 1250,     // Tiempo total
    "totalKeysExamined": 50000,      // Claves de índice examinadas
    "totalDocsExamined": 50000,      // Documentos leídos
    "nReturned": 1234,               // Documentos devueltos
    "executionStages": {
      "stage": "COLLSCAN",           // ¡PROBLEMA! Scan completo
      "direction": "forward"
    }
  }
}
```

En este ejemplo, vemos un **COLLSCAN** (collection scan), lo que significa que MongoDB tuvo que examinar 50,000 documentos para devolver solo 1,234. El ratio de eficiencia es pésimo (50000/1234 = 40.5). Una consulta eficiente debería tener un ratio cercano a 1, lo que indica que casi todos los documentos examinados fueron devueltos.

**Solución: crear índice compuesto:**

```javascript
db.pedidos.createIndex({ estado: 1, fecha: 1 })

// Ahora la misma consulta:
{
  "executionStats": {
    "executionTimeMillis": 23,       // ¡50x más rápido!
    "totalKeysExamined": 1234,
    "totalDocsExamined": 1234,
    "nReturned": 1234,
    "executionStages": {
      "stage": "IXSCAN",             // Usa índice
      "indexName": "estado_1_fecha_1"
    }
  }
}
```

**Métricas de disco (I/O):**

El rendimiento del disco afecta directamente a la velocidad de MongoDB: [last9](https://last9.io/blog/mongodb-performance-metrics/)

```javascript
db.serverStatus().wiredTiger.blockManager
{
  "blocks read": 2345678,
  "blocks written": 1234567,
  "bytes read": 96234567890,        // ~89GB leídos
  "bytes written": 45678901234,     // ~42GB escritos
  "bytes written for checkpoint": 34567890123
}
```

Para sistemas en producción, deberíamos monitorizar también desde el sistema operativo:

```bash
# Linux: iostat para ver uso de disco
iostat -x 5  # Actualizar cada 5 segundos

Device  r/s    w/s    rkB/s   wkB/s   await  %util
sda     234.5  123.2  14567   8901    5.2    78.5
```

Si `%util` está constantemente por encima del 80%, tenemos un cuello de botella de I/O. Soluciones:
- Migrar a SSDs NVMe (10-20x más rápidos que SSDs SATA)
- Aumentar la caché de WiredTiger
- Optimizar índices para reducir lecturas de disco

**Métricas de replicación:**

En un Replica Set, el lag de replicación es crítico: [satoricyber](https://satoricyber.com/mongodb-security/mongodb-monitoring-12-metrics-you-cant-ignore/)

```javascript
rs.printReplicationInfo()
// Salida:
configured oplog size:   10240MB
log length start to end: 86394s (23.9hrs)
oplog first event time:  Sat Feb 08 2026 12:00:00 GMT+0100
oplog last event time:   Sun Feb 09 2026 11:59:54 GMT+0100

rs.printSecondaryReplicationInfo()
// Salida:
source: mongo2.ejemplo.com:27017
  syncedTo: Sun Feb 09 2026 17:14:23 GMT+0100
  0 secs (0 hrs) behind the primary

source: mongo3.ejemplo.com:27017
  syncedTo: Sun Feb 09 2026 17:13:45 GMT+0100
  38 secs (0.01 hrs) behind the primary  // ¡Retraso!
```

Un retraso de más de 30 segundos en producción es preocupante. Causas comunes:
- Red lenta entre nodos
- Secundario con hardware inferior
- Carga alta de lectura en el secundario (si permite lecturas)
- Operaciones de escritura muy grandes

**Herramientas de monitorización externa:**

**Prometheus + Grafana:**

Prometheus puede scrape métricas de MongoDB usando el exportador oficial:

```bash
# Iniciar mongodb_exporter
./mongodb_exporter --mongodb.uri="mongodb://monitor_user:password@localhost:27017"
```

Luego configurar Prometheus para recolectar métricas cada 15 segundos y visualizarlas en Grafana con dashboards predefinidos que muestran todas las métricas en tiempo real.

**MongoDB Atlas (para entornos cloud):**

Si usamos Atlas, obtenemos monitorización completa integrada con alertas automáticas, incluyendo:
- Performance Advisor que sugiere índices faltantes
- Query Profiler visual
- Alertas configurables (CPU > 80%, memoria > 90%, etc.)
- Análisis de conexiones y slow queries

### **4.2. Gestión de logs y rotación**

Los logs de MongoDB son esenciales para diagnóstico y auditoría. Por defecto, MongoDB escribe logs en formato JSON estructurado desde la versión 4.4+, lo que facilita su análisis.

**Niveles de verbosidad:**

MongoDB permite configurar la verbosidad global y por componente:

```javascript
// Ver configuración actual de log
db.getLogComponents()

// Aumentar verbosidad de queries para debugging
db.setLogLevel(2, "query")

// Aumentar verbosidad de replicación
db.setLogLevel(3, "replication")

// Restaurar a valores por defecto
db.setLogLevel(0)
```

**Niveles de log:**
- **0 (INFO)**: Operaciones importantes, arranque, paradas
- **1-2 (DEBUG)**: Información de debugging útil
- **3-5 (TRACE)**: Extremadamente verboso, solo para desarrollo

**Ejemplo de entrada de log:**

```json
{
  "t": {"$date": "2026-02-09T17:14:32.123+01:00"},
  "s": "I",  // Severity: I=Info, W=Warning, E=Error
  "c": "COMMAND",  // Component
  "id": 51803,
  "ctx": "conn42",
  "msg": "Slow query",
  "attr": {
    "type": "find",
    "ns": "ventas.pedidos",
    "command": {
      "find": "pedidos",
      "filter": {"total": {"$gt": 1000}}
    },
    "planSummary": "COLLSCAN",
    "durationMillis": 2345
  }
}
```

**Análisis de logs para identificar problemas:**

```bash
# Encontrar todas las slow queries (>1 segundo)
grep -E '"durationMillis":[0-9]{4,}' /var/log/mongodb/mongod.log

# Encontrar errores de conexión
grep '"s":"E"' /var/log/mongodb/mongod.log | grep "connection"

# Contar tipos de operaciones lentas
grep "Slow query" /var/log/mongodb/mongod.log | \
  grep -oE '"type":"[^"]*"' | sort | uniq -c | sort -rn
```

**Rotación de logs:**

Para evitar que los logs consuman todo el disco:

```yaml
# En mongod.conf
systemLog:
  destination: file
  path: /var/log/mongodb/mongod.log
  logRotate: reopen  # Rotar cuando reciba SIGUSR1
  logAppend: true
```

Script de rotación manual:

```bash
#!/bin/bash
# /usr/local/bin/rotate-mongodb-logs.sh

LOG_DIR="/var/log/mongodb"
TIMESTAMP=$(date +%Y%m%d-%H%M%S)

# Renombrar log actual
mv ${LOG_DIR}/mongod.log ${LOG_DIR}/mongod.log.${TIMESTAMP}

# Señalar a MongoDB para que cree nuevo log
kill -SIGUSR1 $(cat /var/run/mongodb/mongod.pid)

# Comprimir log antiguo
gzip ${LOG_DIR}/mongod.log.${TIMESTAMP}

# Eliminar logs de más de 30 días
find ${LOG_DIR} -name "mongod.log.*.gz" -mtime +30 -delete
```

### **4.3. Backup y restauración**

Una estrategia de backup sólida es fundamental para cualquier sistema de producción. MongoDB ofrece varias opciones, cada una con sus pros y contras. [severalnines](https://severalnines.com/blog/a-comparison-of-mongodb-backup-strategies/)

**Tipos de backup:**

**1. Backups lógicos con mongodump/mongorestore:**

Este método exporta los datos en formato BSON: [percona](https://www.percona.com/blog/mongodb-backup-best-practices/)

```bash
# Backup completo de todas las bases de datos
mongodump --host=localhost --port=27017 \
  --username=backup_user --password=backup_pass \
  --authenticationDatabase=admin \
  --out=/backup/dump-$(date +%Y%m%d)

# Backup de una base de datos específica con compresión
mongodump --db=ventas --gzip \
  --archive=/backup/ventas-$(date +%Y%m%d).gz

# Backup con oplog (para point-in-time recovery)
mongodump --oplog --gzip \
  --archive=/backup/full-with-oplog-$(date +%Y%m%d).gz
```

**Ventajas:**
- Independiente de la versión de MongoDB (compatible entre versiones)
- Permite backup selectivo (bases de datos o colecciones específicas)
- Puede ejecutarse sin detener el servicio

**Desventajas:**
- Lento para bases de datos grandes (>100GB)
- No captura el estado exacto en un punto del tiempo (a menos que se use --oplog)
- Alto uso de CPU durante el backup

**Restauración con mongorestore:**

```bash
# Restaurar todas las bases de datos
mongorestore --gzip --archive=/backup/full-20260209.gz

# Restaurar una base de datos específica
mongorestore --db=ventas --gzip \
  --archive=/backup/ventas-20260209.gz

# Restaurar con replay de oplog (point-in-time)
mongorestore --oplogReplay --gzip \
  --archive=/backup/full-with-oplog-20260209.gz
```

**2. Backups físicos (filesystem snapshots):**

Copian directamente los archivos de datos: [percona](https://www.percona.com/blog/mongodb-backup-best-practices/)

```bash
# 1. Flush y lock (solo si es standalone o secundario)
mongo admin --eval "db.fsyncLock()"

# 2. Crear snapshot (ejemplo con LVM)
lvcreate --size 10G --snapshot --name mongodb-snap /dev/vg0/mongodb-data

# 3. Unlock
mongo admin --eval "db.fsyncUnlock()"

# 4. Montar snapshot y copiar
mkdir /mnt/snapshot
mount /dev/vg0/mongodb-snap /mnt/snapshot
tar czf /backup/mongodb-physical-$(date +%Y%m%d).tar.gz /mnt/snapshot

# 5. Limpiar
umount /mnt/snapshot
lvremove -f /dev/vg0/mongodb-snap
```

**Ventajas:**
- Extremadamente rápido, incluso para terabytes
- Captura estado consistente del disco

**Desventajas:**
- Requiere parar escrituras (o hacer snapshot de un secundario)
- Dependiente de la plataforma de almacenamiento

**3. Cloud snapshots:**

Si MongoDB está en la nube (AWS, GCP, Azure), usar snapshots nativos:

```bash
# AWS - snapshot de volumen EBS
aws ec2 create-snapshot \
  --volume-id vol-1234567890abcdef0 \
  --description "MongoDB backup $(date +%Y%m%d)"
```

**Estrategia de backup recomendada para producción:**

```
Diario:
  - Backup lógico con mongodump (conservar 7 días)
  - Ejecutar en un secundario para no afectar el primario

Semanal:
  - Snapshot físico (conservar 4 semanas)
  
Mensual:
  - Backup completo archivado (conservar 12 meses)
  - Verificar integridad restaurando en un entorno de test

Continuous:
  - Backup incremental del oplog (para PITR)
  - Sincronizar a almacenamiento offsite (S3, Google Cloud Storage)
```

**Ejemplo de script de backup automatizado:**

```bash
#!/bin/bash
# /usr/local/bin/mongodb-backup.sh

BACKUP_DIR="/backup/mongodb"
RETENTION_DAYS=7
MONGO_URI="mongodb://backup_user:pass@localhost:27017/?authSource=admin"

# Crear directorio con fecha
TODAY=$(date +%Y%m%d)
BACKUP_PATH="${BACKUP_DIR}/${TODAY}"
mkdir -p ${BACKUP_PATH}

# Ejecutar backup
mongodump --uri="${MONGO_URI}" \
  --oplog \
  --gzip \
  --archive="${BACKUP_PATH}/dump.gz"

# Verificar que el backup se completó correctamente
if [ $? -eq 0 ]; then
  echo "[$(date)] Backup exitoso: ${BACKUP_PATH}/dump.gz" >> /var/log/mongodb-backup.log
  
  # Sincronizar a S3
  aws s3 sync ${BACKUP_PATH} s3://mi-bucket-backup/mongodb/${TODAY}/
  
  # Eliminar backups antiguos
  find ${BACKUP_DIR} -type d -mtime +${RETENTION_DAYS} -exec rm -rf {} \;
else
  echo "[$(date)] ERROR en backup" >> /var/log/mongodb-backup.log
  # Enviar alerta por email o Slack
  mail -s "MongoDB Backup Failed" admin@ejemplo.com < /dev/null
fi
```

**Configurar en crontab:**

```bash
# Backup diario a las 2 AM
0 2 * * * /usr/local/bin/mongodb-backup.sh
```

### **4.4. Gestión de índices y optimización**

Los índices son cruciales para el rendimiento de MongoDB. Un índice bien diseñado puede reducir el tiempo de consulta de segundos a milisegundos, mientras que índices mal diseñados o innecesarios desperdician espacio y ralentizan las escrituras. [djamware](https://www.djamware.com/post/690ec5c6efda8f3894ed87b8/mongodb-performance-tuning-indexing-and-optimization-best-practices)

**Principios de diseño de índices:**

**Regla ESR (Equality, Sort, Range):**

Al diseñar índices compuestos, el orden óptimo de campos es: [djamware](https://www.djamware.com/post/690ec5c6efda8f3894ed87b8/mongodb-performance-tuning-indexing-and-optimization-best-practices)

1. **Equality**: Campos con condiciones de igualdad (`campo: valor`)
2. **Sort**: Campos usados para ordenar
3. **Range**: Campos con condiciones de rango (`$gt`, `$lt`, `$in`)

**Ejemplo práctico:**

```javascript
// Consulta típica de una aplicación
db.pedidos.find({
  estado: "completado",           // Equality
  cliente_id: { $in: ["C1","C2"] },  // Range
  total: { $gte: 100 }           // Range
}).sort({ fecha: -1 })            // Sort

// Índice subóptimo (orden incorrecto)
db.pedidos.createIndex({ fecha: -1, estado: 1, total: 1 })

// Índice óptimo siguiendo ESR
db.pedidos.createIndex({ estado: 1, fecha: -1, total: 1 })
// Equality primero, luego Sort, finalmente Range
```

**Tipos de índices especializados:**

**Índices parciales (partial indexes):**

Solo indexan documentos que cumplen cierta condición, ahorrando espacio: [chat2db](https://chat2db.ai/resources/blog/how-to-optimize-mongodb-indexing)

```javascript
// Solo indexar pedidos activos (90% son históricos)
db.pedidos.createIndex(
  { cliente_id: 1, fecha: -1 },
  { 
    partialFilterExpression: { 
      estado: { $in: ["pendiente", "procesando"] }
    },
    name: "idx_pedidos_activos"
  }
)

// Este índice solo ocupa 10% del espacio de un índice completo
// pero sirve eficientemente las consultas de pedidos activos
```

**Índices sparse (dispersos):**

Omiten documentos donde el campo indexado no existe:

```javascript
// Campo opcional que solo el 5% de documentos tiene
db.productos.createIndex(
  { fecha_descuento: 1 },
  { sparse: true }
)

// Ahorra 95% del espacio comparado con índice normal
```

**Índices TTL (Time To Live):**

Eliminan automáticamente documentos antiguos:

```javascript
// Eliminar logs después de 30 días
db.logs.createIndex(
  { timestamp: 1 },
  { expireAfterSeconds: 2592000 }  // 30 días
)

// MongoDB elimina documentos automáticamente cada 60 segundos
```

**Índices de texto (text indexes):**

Para búsquedas de texto completo:

```javascript
// Indexar múltiples campos de texto
db.articulos.createIndex({
  titulo: "text",
  contenido: "text",
  tags: "text"
}, {
  weights: {
    titulo: 10,      // Título es más relevante
    contenido: 5,
    tags: 2
  },
  name: "idx_busqueda_articulos"
})

// Búsqueda
db.articulos.find({
  $text: { $search: "mongodb administración" }
}, {
  score: { $meta: "textScore" }
}).sort({ score: { $meta: "textScore" } })
```

**Identificación de índices faltantes:**

```javascript
// Habilitar profiler para capturar queries lentas
db.setProfilingLevel(1, { slowms: 100 })

// Después de un tiempo, analizar queries sin índice
db.system.profile.find({
  millis: { $gt: 100 },
  planSummary: "COLLSCAN"
}).sort({ ts: -1 }).limit(10)
```

**Identificación de índices no utilizados:**

```javascript
// Ver estadísticas de uso de índices
db.pedidos.aggregate([
  { $indexStats: {} }
])

// Salida muestra accesses desde el último reinicio
{
  "name": "estado_1_fecha_-1",
  "key": { "estado": 1, "fecha": -1 },
  "accesses": {
    "ops": 45123,
    "since": ISODate("2026-02-01T00:00:00Z")
  }
},
{
  "name": "cliente_legado_1",  // ¡0 accesos!
  "key": { "cliente_legado": 1 },
  "accesses": {
    "ops": 0,
    "since": ISODate("2026-02-01T00:00:00Z")
  }
}

// Eliminar índice no utilizado
db.pedidos.dropIndex("cliente_legado_1")
```

**Costo de los índices:**

Cada índice tiene un costo en espacio y rendimiento de escritura: [djamware](https://www.djamware.com/post/690ec5c6efda8f3894ed87b8/mongodb-performance-tuning-indexing-and-optimization-best-practices)

```javascript
// Ver tamaño de índices
db.pedidos.stats().indexSizes
{
  "_id_": 52428800,              // 50MB
  "estado_1_fecha_-1": 104857600, // 100MB
  "cliente_1": 83886080          // 80MB
  // Total: 230MB solo en índices para una colección de 500MB
}
```

**Regla práctica:** No crear más de 5-7 índices por colección. Cada índice adicional ralentiza inserts/updates/deletes proporcionalmente.

**Rebuild de índices (cuando es necesario):**

Generalmente no es necesario en MongoDB moderno, pero puede ayudar si:
- Índice fragmentado después de muchas actualizaciones
- Liberación de espacio después de eliminar muchos documentos

```javascript
// Rebuild en foreground (bloquea la colección)
db.pedidos.reIndex()

// Mejor: rebuild en background (no bloquea)
db.pedidos.dropIndex("estado_1_fecha_-1")
db.pedidos.createIndex({ estado: 1, fecha: -1 }, { background: true })
```

Con una monitorización efectiva y un mantenimiento proactivo, podemos mantener MongoDB funcionando óptimamente y detectar problemas antes de que afecten a los usuarios. En el siguiente capítulo, comenzaremos a explorar el escalado horizontal mediante Replica Sets.

***

¿Continuamos con el Capítulo 5?