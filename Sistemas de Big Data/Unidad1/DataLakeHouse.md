## Qu√© es un **Data Lakehouse**

Un **Data Lakehouse** es una **arquitectura h√≠brida** que une lo mejor de los dos mundos:

| Caracter√≠stica | Data Warehouse                                | Data Lake                            | **Data Lakehouse**                 |
| -------------- | --------------------------------------------- | ------------------------------------ | ---------------------------------- |
| Tipo de datos  | Estructurados (tablas, SQL)                   | Todos (crudos, JSON, im√°genes, logs) | Todos                              |
| Modelo         | Schema-on-write (transformo antes de guardar) | Schema-on-read (transformo al leer)  | H√≠brido                            |
| Procesamiento  | ETL                                           | ELT                                  | ETL y ELT                          |
| Coste          | Alto                                          | Bajo                                 | Moderado                           |
| Rendimiento    | Muy alto (consultas SQL optimizadas)          | Bajo (archivos crudos)               | Alto (usa √≠ndices y formatos ACID) |
| Casos de uso   | BI, reporting                                 | Machine Learning, an√°lisis libre     | Ambos                              |

En resumen:

> El Data Lakehouse **mantiene la flexibilidad** y bajo coste del *Data Lake*, pero **a√±ade estructura, transacciones ACID y rendimiento tipo Data Warehouse.**

---

## C√≥mo funciona internamente

Imagina que tienes un **Data Lake** en la nube (por ejemplo, **Amazon S3**, **Azure Data Lake Storage** o **Google Cloud Storage**) donde guardas todos tus datos crudos.

El *Lakehouse* a√±ade tres capas encima de ese almacenamiento:

### 1Ô∏è‚É£ **Capa de almacenamiento base**

* Guarda los datos en bruto (archivos Parquet, ORC, Avro, etc.).
* Es escalable y barata (almacenamiento de objetos).
* Ejemplo: `/raw/sensores/2025-10-06/temperatura.parquet`.

### 2Ô∏è‚É£ **Capa de metadatos y transacciones (ACID)**

* A√±ade un **cat√°logo de tablas** (como en un Data Warehouse) sobre esos archivos.
* Permite hacer **consultas SQL** como si fuera una base de datos.
* Gestiona **transacciones ACID**, control de versiones y *time travel* (puedes consultar los datos ‚Äúcomo estaban‚Äù ayer).
* Ejemplos de formatos que a√±aden esta magia:

  * **Delta Lake** (Databricks)
  * **Apache Iceberg** (Netflix, Snowflake)
  * **Apache Hudi** (Uber)

### 3Ô∏è‚É£ **Capa de acceso unificado**

* Herramientas como **Spark SQL**, **Power BI**, **Tableau**, **Presto**, **Trino** o **Databricks SQL** pueden leer directamente las ‚Äútablas del lago‚Äù.
* Puedes correr *Machine Learning* y *BI* sobre el mismo dataset, sin duplicar datos.


## üîç Ejemplo real

### Caso: **Netflix**

* Tiene un **Data Lake** gigante en Amazon S3 con logs, clics, v√≠deos, etc.
* Usa **Apache Iceberg** como formato de tabla sobre S3.
* Esto convierte esos archivos en **tablas transaccionales**, consultables por Spark, Presto, Trino o Snowflake.
* As√≠ pueden:

  * Hacer *reporting* (BI cl√°sico).
  * Entrenar modelos de recomendaci√≥n con *Machine Learning*.
  * Todo sin mover ni duplicar los datos.


## üåü Ejemplos de **Data Lakehouse famosos**

| Plataforma                             | Tecnolog√≠a             | Descripci√≥n                                                                          |
| -------------------------------------- | ---------------------- | ------------------------------------------------------------------------------------ |
| **Databricks Lakehouse**               | **Delta Lake**         | El m√°s famoso. Mezcla Spark, ML, BI y streaming sobre un mismo lago (S3, ADLS, GCS). |
| **Snowflake Arctic / Polaris Catalog** | **Iceberg**            | Ha adoptado formato abierto y lo combina con motor SQL propietario.                  |
| **Google BigLake**                     | **Iceberg + BigQuery** | Fusiona BigQuery con Data Lake abierto en GCS.                                       |
| **AWS Athena + Glue + S3**             | **Iceberg o Hudi**     | Crea un Lakehouse barato con herramientas nativas de AWS.                            |
| **Apache Hudi (Uber)**                 | **Hudi Tables**        | Permite *upserts* y *time travel* en lagos de datos a gran escala.                   |

